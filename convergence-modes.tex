\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{float}
\usepackage{microtype}
\usepackage{tikz}

\newcommand \dP {\;\mathrm{d}\mathbb{P}}


\title{Modes of Convergence}
\author{William G Underwood}

\begin{document}

\maketitle

\section{Introduction}

In probability theory, we use several notions of `convergence' for
a sequence of random variables.
Some of these notions are stronger than others, so it is natural to ask
exactly when one convergence implies another.
In the following definitions and results, we assume that $X$ and $(X_n)_{n \geq 1}$ are all
random variables on some complete probability space $(\Omega, \mathcal{F}, \mathbb{P})$.


\section{Definitions}

Below are definitions for a few of the more
commonly-used modes of convergence.
Other notions include
almost uniform convergence

\subsection*{Almost sure convergence ($a.s.$)}

$X_n \xrightarrow{a.s.} X$
if
$$\mathbb{P}(X_n \to X \text{ as } n \to \infty) = 1$$

\subsection*{Convergence in probability ($\mathbb{P}$)}

$X_n \xrightarrow{\mathbb{P}} X$
if for all $\epsilon > 0$,
as $n \to \infty$,
$$\mathbb{P}(|X_n - X| > \epsilon) \to 0$$

\subsection*{Convergence in distribution ($d$)}

$X_n \xrightarrow{d} X$
if for all continuous $f: \mathbb{R} \to \mathbb{R}$,
as $n \to \infty$,
$$\mathbb{E}[f(X_n)] \to \mathbb{E}[f(X)]$$

\subsection*{Convergence in $L^p$, for $1 \leq p < \infty$}

$X_n \xrightarrow{L^p} X$
if as $n \to \infty$,
$$\mathbb{E}[|X_n - X|^p] \to 0$$

\subsection*{Convergence in $L^\infty$}
First define $\|X\|_\infty = \inf\{M: |X| \leq M \text{ almost surely}\}$.
Then $X_n \xrightarrow{L^\infty} X$
if as $n \to \infty$,
$$\|X_n - X\|_\infty \to 0$$

\subsection*{Notes on definitions}

Almost sure convergence is the natural extension of the
notion of pointwise convergence of functions.
We simply require the convergence to occur at almost every point rather
than at every point.

Convergence in probability is (as we will see) weaker than this, and means that
with high probability, $(X_n)$ will not make large deviations from $X$.

Convergence in distribution is even weaker, and depends only on the
distributions of the random variables.
The random variables do not even need to be defined on the same probability space.

The $L^p$ modes define a whole family of convergences, with a larger value of $p$ giving
stronger convergence.


\section{Results}

All of the results are summarised in Figure~\ref{fig:diagram}.
Arrows indicate strength of convergence.


\begin{figure}[H]
\centering
\begin{tikzpicture}

  % nodes
  \node at (0,0) {\huge $L^\infty$};
  \node at (2,2) {\huge $L^p$};
  \node at (5,2) {\huge $L^1$};
  \node at (7,0) {\huge $\mathbb{P}$};
  \node at (10,0) {\huge $d$};
  \node at (3.5,-2) {\huge $a.s.$};

  % arrows
  \draw [->, very thick] (0,0.7) to [out=80,in=190] (1.3,1.9);
  \draw [->, very thick] (2.7,2) -- (4.3,2);
  \draw [->, very thick] (5.7,1.9) to [out=-10,in=100] (6.9,0.7);
  \draw [->, very thick, dashed] (6.3,0) to [out=170,in=-80] (5,1.3);
  \draw [->, very thick] (7.7,0) -- (9.3,0);
  \draw [->, very thick] (0,-0.7) to [out=-60,in=170] (2.7,-2);
  \draw [->, very thick] (4.3,-2) to [out=10,in=-120] (6.8,-0.7);

  % labels
  \node[circle,draw,inner sep=2pt] at (0,1.8) {1};
  \node[circle,draw,inner sep=2pt] at (3.4,2.5) {2};
  \node[circle,draw,inner sep=2pt] at (7,1.8) {3};
  \node[circle,draw,inner sep=2pt] at (5,0) {4};
  \node[circle,draw,inner sep=2pt] at (0.7,-2) {5};
  \node[circle,draw,inner sep=2pt] at (6.3,-2) {6};
  \node[circle,draw,inner sep=2pt] at (8.4,0.5) {7};

\end{tikzpicture}
\caption{Modes of Convergence}\label{fig:diagram}
\end{figure}


\section{Proofs}

A proof is given for each arrow in Figure~\ref{fig:diagram}.

\subsection*{1. $L^\infty$ convergence implies $L^p$ convergence}
\begin{align*}
  \mathbb{E}[|X_n - X|^p]
  &= \int_\Omega |X_n - X|^p \dP \\
  &\leq \|X_n - X\|_\infty \int_\Omega \dP \\
  &\to 0
\end{align*}


\subsection*{2. $L^p$ convergence implies $L^1$ convergence}


\end{document}
